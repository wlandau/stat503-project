---
title: "What distinguishes high-performing students?"
author: Will Landau
date: April 6, 2015
output: 
  pdf_document:
    fig_caption: true
bibliography: report.bib
---

```{r, echo=FALSE}
library(knitr)
knitr::knit_hooks$set(inline = as.character)
knitr::opts_chunk$set(cache=T, fig.height = 4, echo = F, results="hide", message = F)
knitr::opts_knit$set(eval.after = 'fig.cap')
```

# Introduction 

The goal is to find and derive variables in the 2012  OECD PISA dataset that separate the highest-performing students from the lowest-performing ones in the United States.  

In 2012, the Organization for Economic Co-operation and Development (OECD) Programme for International Student Assessment (PISA) surveyed roughly five hundred thousand, fifteen-year-old students from sixty-five economies across the globe [@oecd]. Questions measured students' reading, math, and science skills in ways that, according to the OECD website, "are not directly linked to the school curriculum. The tests are designed to assess to what extent students at the end of compulsory education, can apply their knowledge to real-life situations and be equipped for full participation in society" [@oecd]. Students also answered extensive background questionnaires about their study habits, attitudes towards school, circumstances at home, etc. Extensive data were recorded about the schools and parents of those students as well.

Using the PISA math and reading scores, I will select the USA students scoring below the 25th percentile overall (low achievers) and the ones scoring above the 75th percentile (high achievers). Next, I will comb through the rest of the student-specific PISA and look for variables that can recover the achievement level (high or low) of each student. Using the most important variables, I will use supervised learning techniques to attempt to classify students, and I will explore the preprocessed data using unsupervised learning techniques. 

# Exploratory analysis

The student-specific data has roughly five hundred variables for predicting reading and math scores. After removing the few numerical variables and the ones with all missing values, we are left with 256 categorical variables for prediction. As seen in Figure \ref{fig:missing}, most variables still have a large fraction of missing values.

```{r sources}
for(f in paste("../R/", c(
  "getData",
  "explore_matching"
), ".R", sep=""))
  source(f)
```

```{r missing, fig.cap="\\label{fig:missing} Histogram of the percentage of missing values in each of the available non-null 256 student-specific categorical variables for prediction. Most variables have a large fraction of missing values."}
missing.hist()
```

The next task is to efficiently comb through the 256 variables and select the ones most suitable for predicting student performance. I rank the variables according to a simple matching heuristic, which I calculate for each factor variable $x$ as follows:

1. Remove the missing values from $x$, along with the corresponding values from the binary vector $y$ of student performances (high and low coded as 1 and 0, respectively).
2. For every subset $s$ of the levels of $x = (x_1, \ldots, x_n)$:
    a. Create the binary vector $z = (z_1, \ldots, z_n)$, where $z_i = I(x_i \in s)$.
    b.  Let the matching score of $s$ be
\begin{align*}
\frac{1}{n} \max \left \{\sum_{i=1}^n I(y_i = z_i), \ \sum_{i=1}^n I(y_i \ne z_i) \right \}
\end{align*}

3. Take the matching score of $x$ to be the maximum of all the matching scores calculated in step 2. 


We can interpret this matching score as a potential rate of correct classification. A matching of 1 means that $x$ can predict $y$ perfectly, and a rate of 0.5 means that $x$ is no better than chance.

Figure \ref{fig:allmatchings} shows the matching scores of all 256 candidate factors. Most variables are better than chance, and the best have matching scores between 0.7 and 0.8. 

```{r allmatchings, fig.cap="\\label{fig:allmatchings} matching scores of all 256 candidate factors. Most variables are better than chance, and the best have matching scores between 0.7 and 0.8. "}
student.factor.matchings.plot()
```

# Variable selection and preprocessing

Figure \ref{fig:goodmatchings} shows the matching scores of the top 40 variables. In general, self-efficacy and prior familiarity with the content most closely match outcomes in performance. However, using these variables for prediction would be logically circular and uninformative from a policy standpoint. I remove them from the analysis. Figure \ref{fig:keepvars} shows the variables with which I will build a classifier.

```{r goodmatchings, fig.height = 8, fig.cap="\\label{fig:goodmatchings} "}
student.factor.matchings.plot(n = 40, y.arg ="Description")
```

```{r keepvars, fig.cap="\\label{fig:keepvars} "}
student.factor.matchings.plot(n = 20, y.arg ="Description", cheatvars = F)
```

Unfortunately, even with a reduction in the number of variables, there are still a lot of missing values. Figure \ref{fig:studentmiss} show the number of missing values for each student. The figure leads to the following imputation strategy:

```{r studentmiss, fig.cap="\\label{fig:studentmiss} number of missing values for each student. This is after selecting the best 20 variables in the \"Variable selection and preprocessing\" section."}
missingByStudent()
```

1. Remove the students who missed more than 13 questions (only 3.4\% of USA students). 
2. Put all factors on a numeric scale such that the natural ordering of factor levels is preserved. (All factors are ordinal.) Center and scale the predictor variables, and denote student performance by 1 and -1 for high-performing and low-performing students, respectively.
3. Impute the remaining missing values with nearest neighbor imputation on the 20 predictor variables. I use the ``knnImputation`` function in the ``DMwR`` [@DMwR] package (setting the number of neighbors to 10).


The resulting dataset looks like:

```{r imputedUSA, results=T, echo = T}
imp = imputedUSA()
dim(imp)
head(imp)
```

where the 20 predictor variables are defined in the PISA 2012 student dictionary.

# Plan for further work

- Flesh out a more comprehensive coherent story in the exploratory analysis section. I will categorize variables by the major issues to which they pertain and group them by the matching coefficients described previously. This will give me a rough idea of which overall issues (such as parental education, possessions, attitude, etc.) are most important in classifying students.
- Build a classifier on the preprocessed and imputed data using:
    - Logistic regression
    - Neural networks
    - Random forests
    - Nearest neighbors classification
- Run a basic clustering analysis on the 20 predictor variables in the imputed data. I will use kmeans and hierarchical clustering, and I will determine how much information about student performance these techniques recover.


# Acknowledgements

I would like to thank Dr. Cook for steering me in the right direction. The PISA data is messy and cumbersome, and she gave me a much-needed boost.


# References
