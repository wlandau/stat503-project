---
title: "What distinguishes high-performing students?"
author: Will Landau
date: April 25, 2015
output: 
  pdf_document:
    fig_caption: true
    number_sections: true
bibliography: report.bib
---

```{r, echo=FALSE}
set.seed(0)
library(knitr)
knitr::knit_hooks$set(inline = as.character)
knitr::opts_chunk$set(cache=T, fig.height = 4, echo = F, results="hide", message = F)
knitr::opts_knit$set(eval.after = 'fig.cap')
```

```{r sources}
for(f in paste("../R/", c(
  "student",
  "issue",
  "subsets",
  "explore"
), ".R", sep=""))
  source(f)
```

# Introduction 

Which factors best separate successful students from those who struggle? How well can we predict academic success using  conditions we can observe and control? For insight, I look at data from the Organization for Economic Co-operation and Development (OECD). In 2012, The OECD's Programme for International Student Assessment (PISA) surveyed roughly five hundred thousand, fifteen-year-old students from sixty-five economies across the globe [@oecd]. Questions measured students' reading, math, and science skills with examinations that, according to the OECD website, "are not directly linked to the school curriculum. The tests are designed to assess to what extent students at the end of compulsory education, can apply their knowledge to real-life situations and be equipped for full participation in society" [@oecd]. Students also answered extensive background questionnaire about their study habits, attitudes towards school, circumstances at home, etc., al of which are factors that may influence student success. In the analysis below, I derive a "student success" variable from the reading and math scores and attempt to predict success using information from the background questionnaire.



# A first cleanup: getting ready to explore

The student-specific 2012 PISA dataset is large and messy, and it needs to be cleaned and subsetted both before and after exploratory analysis. For example, to save computing time, and because overall pedagogy and the survey's implementation are different among different countries, only students from the United States will be examined here.

## Variables for predicting success

There are around 500 variables from the student background questionnaire, and large fraction of the answers are missing. In fact, after removing the few continuous survey variables and the questions with no recorded responses at all, only 256 variables are left. Of those 256, I remove the ones that probably cannot help education policy, such as self-efficacy measures, self-reported prior familiarity and experience with math and reading concepts, and nondescript "ISCED" variables. 210 factor variables remain for prediction, most of which have between 2 and 4 levels each.


## Measuring student success

For each student, the PISA dataset has 5 overall reading scores and 5 overall math scores. Each score is roughly on a continuous scale from around 200 to around 800, and as seen in Figure \ref{fig:pv}, the scores are highly correlated. Standardized test scores are only rough measures of academic performance, but when properly censored, they do expose the most egregious achievement gaps. To censor the data, I

1. Compute a total score for each student by summing the 10 standardized PISA scores together.
2. Collect the students with total scores above the 75th percentile, and call them "high-performing".
3. Collect the students with total scores below the 25th percentile, and call them "low-performing".
4. Remove the rest of the students from the data.

In the context of prediction, I now have a response variable with two possible values: high and low. I will temporarily suspend my skepticism and treat this factor as the gold standard of student success. 

```{r pv, fig.cap="\\label{fig:pv}histogram of pairwise correlations among the original 5 reading and 5 math scores from the PISA tests. Correlations are high, so I do not lose much information in summing them up to produce a single total score for each student."}
  pvcor()
```

# The best general issues for predicting success

In this section, I attempt to find the general issues that have the highest potential of distinguishing successful students from those who struggle.

## Ranking individual predictor variables

To get a rough picture of the important issues, I first rank all 210 variables individually. For the rankings, I use a matching heuristic that loosely measures how well a factor can split students by success level. For each factor $x$, I calculate this heuristic as follows. 

1. Remove the missing values from $x$, along with the corresponding values from the binary vector $y$ of student performances (high and low coded as 1 and 0, respectively).
2. For every subset $s$ of the levels of $x = (x_1, \ldots, x_n)$,
    a. Create the binary vector $z = (z_1, \ldots, z_n)$, where $z_i = I(x_i \in s)$.
    b. Let the matching score of $s$ be
\begin{align*}
\frac{1}{n} \max \left \{\sum_{i=1}^n I(y_i = z_i), \ \sum_{i=1}^n I(y_i \ne z_i) \right \}
\end{align*}

3. Take the matching score of $x$ to be the maximum of all the matching scores calculated in step 2. 


One can interpret the matching heuristic as the most optimistic rate of correct classification for a prediction on a single variable. A matching of 1 means that $x$ can predict $y$ perfectly, and a matching of 0.5 means that $x$ is no better than chance.

Figure \ref{fig:allmatchings} shows the matching heuristics of the 210 predictor variables. Most individual variables predict better than chance. The two variables with matchings better than 0.7 are "How many books at home" (censored) and "Vignette Classroom Management - Students Frequently Interrupt/Teacher Arrives Late".

```{r allmatchings, fig.cap="\\label{fig:allmatchings} matching heuristics of all 210 predictor variables. Most individual variables predict better than chance. The two variables with matchings better than 0.7 are \"How many books at home\" (censored) and \"Vignette Classroom Management - Students Frequently Interrupt/Teacher Arrives Late\"."}
matching.hist()
```

Figure \ref{fig:issue} shows the matching scores of the 210 variables, where the variables are grouped by the general issues they cover, such as possessions, attitudes, teaching, etc. The results are not definitive because the matching scores only apply to separate variables individually. However, we can start to identify potentially useful key issues in education. The three topics with multiple high matching scores are teaching, attitude/interest/motivation, and parental backgrounds. These three issues have high potential for affecting student success, and they are the ones I will continue pursuing in subsequent sections. It is important to recognize here, however, that these issues have the most variables, and their apparent importance could just be due to bias in the design of the PISA survey.

```{r issue, fig.height=6, fig.cap="\\label{fig:issue} matching scores of the 210 variables, where the variables are grouped by the general issues they cover, such as possessions, attitudes, teaching, etc. The results are not definitive because the matching scores only apply to separate variables individually. However, we can start to identify potentially useful key issues in education. The three topics with multiple high matching scores are teaching, attitude/interest/motivation, and parental backgrounds. These three issues have high potential for affecting student success, and they are the ones I will continue pursuing in subsequent sections. It is important to recognize here, however, that these issues have the most variables, and their apparent importance could just be due to bias in the design of the PISA survey."}
plot.matching.by.issue()
```

# Focusing on the key issues

The previous section established that teaching, attitude/interest/motivation, and parental backgrounds could be important areas to investigate. Some matching scores on individual variables in these areas are high. But how important is each key issue overall? Which issues are more important than the others? How does each issue compare to the full predictive potential of the whole PISA dataset? To find out, I build a dataset on each issue and attempt to classify students according to academic success. Below, I describe these issue-specific datasets.

## Issue-specific datasets

### Teaching

The teaching variables measure many different aspects of teaching style and quality as experienced by the students, such as the frequency of homework, quality of feedback, classroom management, the disciplinary climate of the classroom, student-teacher rapport, assessments, and calculator use. For the teaching dataset, I take the teaching variables with the top 20 matching scores, shown in Figure \ref{fig:usateaching}.

```{r usateaching, fig.cap="\\label{fig:usateaching}  For the USA teaching dataset, I take the teaching variables with the top 20 matching scores, shown here."}
matching.dot.plot(country = "USA", .issue = "teaching", n = 20, max.na = 15)
```

### Attitude/interest/motivation

These variables are student self-reported measures of perceived control, work ethic, motivation, attitude towards school, anxiety, attributions to failure, and perseverance. For the attitude/interest/motivation dataset, I take the variables in this area with the top 20 matching scores, shown in Figure \ref{fig:usaattitude}.

```{r usaattitude, fig.cap="\\label{fig:usaattitude}  For the USA attitude/interest/motivation dataset, I take the variables in this area with the top 20 matching scores, shown here."}
matching.dot.plot(country = "USA", .issue = "attitude-interest", n = 20, max.na = 15)
```

### Parental backgrounds

The parental background variables measure the educational levels, job statuses, and "ISCED qualifications" of the parents of each student. (It's a shame that PISA does not explain what these ISCED qualifications really mean. Many nondescript "ISCED" variables are poorly documented.) I use all 15 of these variables for the parental backgrounds dataset, shown in Figure \ref{fig:usaparent}.

```{r usaparent, fig.cap="\\label{fig:usaparent}  The parental background variables measure the educational levels, job statuses, and \"ISCED qualifications\" of the parents of each student. I use all 15 of these variables for the parental backgrounds dataset, shown here."}
matching.dot.plot(country = "USA", .issue = "parent.backgrounds", n = 15, max.na = 12)
```


### Top 20 variables

For the sake of comparison, I collect the variables with the top 20 matching scores out of all the usable 210 factors from the USA PISA student dataset, shown in Figure \ref{fig:usatop20}.

```{r usatop20, fig.cap="\\label{fig:usatop20} For the sake of comparison, I collect the variables with the top 20 matching scores out of all the usable 210 factors from the USA PISA student dataset, shown here."}
matching.dot.plot(country = "USA", .issue = "top_20", n = 20, max.na = 15)
```




# Acknowledgements

I would like to thank Dr. Cook for steering me in the right direction. The PISA data is messy and cumbersome, and the guidance is very appreciated.

# References
